from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import RidgeClassifier
from sklearn.metrics import f1_score

# 法一：
vectorizer = CountVectorizer(max_features=3000)
train_test = vectorizer.fit_transform(train_df['text'])

clf = RidgeClassifier()  # 岭回归分类器
clf.fit(train_test[:190000], train_df['label'].values[:190000])
val_pred = clf.predict(train_test[10000:])
print(f1_score(train_df['label'].values[10000:], val_pred, average='macro'))
# 结果：0.8294123252976843

# 法二
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(ngram_range=(1, 3), max_features=3000)
# ngram_range(min,max)是指将text分成min，min+1，min+2,…max 个不同的词组
train_test = tfidf.fit_transform(train_df['text'])

clf_1 = RidgeClassifier()
clf_1.fit(train_test[:190000], train_df['label'].values[:190000])
val_pred = clf_1.predict(train_test[10000:])
print(f1_score(train_df['label'].values[10000:], val_pred, average='macro'))
# 结果：0.901991098979414

# 更换为随机森林模型
from sklearn.ensemble import RandomForestClassifier
clf_2 = RandomForestClassifier(max_depth=5, random_state=0)
clf_2.fit(train_test[:190000], train_df['label'].values[:190000])
val_pred = clf_2.predict(train_test[10000:])
print(f1_score(train_df['label'].values[10000:], val_pred, average='macro'))
# 结果：0.2625849429374688  效果不好的原因可能在于，这是多分类问题，需做其他的处理
